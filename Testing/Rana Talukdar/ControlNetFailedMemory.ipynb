{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bcd6e7be5b444bb88000a63176a695eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66a7ab1c786f46e587236f08b7e3b079",
              "IPY_MODEL_9d519a348695414c9c8b9da328f37e97",
              "IPY_MODEL_b5df8bc10f3c401cb45b3898a9fde587"
            ],
            "layout": "IPY_MODEL_288e9a2026eb4f7496bd5d3fd47991ab"
          }
        },
        "66a7ab1c786f46e587236f08b7e3b079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b278e708db7c4637b29c26926fcfc1e4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9aeb363eac8e47069992acf1cb716663",
            "value": "Fetching‚Äá15‚Äáfiles:‚Äá100%"
          }
        },
        "9d519a348695414c9c8b9da328f37e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf98bb12e7945518f6568ea49069c28",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac8d68633b454c51946c69b9e67bf7d8",
            "value": 15
          }
        },
        "b5df8bc10f3c401cb45b3898a9fde587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c09ac5d6ea541a9b3a630262aef58b6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_90d9039fc94640d2b5f52cc60f4f7633",
            "value": "‚Äá15/15‚Äá[00:00&lt;00:00,‚Äá31.15it/s]"
          }
        },
        "288e9a2026eb4f7496bd5d3fd47991ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b278e708db7c4637b29c26926fcfc1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aeb363eac8e47069992acf1cb716663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cf98bb12e7945518f6568ea49069c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac8d68633b454c51946c69b9e67bf7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c09ac5d6ea541a9b3a630262aef58b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d9039fc94640d2b5f52cc60f4f7633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6c3d3f691f44f3ea10b5818e97825f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be8bc0b49aae47bb9bd84cb86adba36a",
              "IPY_MODEL_d06f14c053d74be5a02c52f916db3de2",
              "IPY_MODEL_26541e90673d476798f020b421c5c750"
            ],
            "layout": "IPY_MODEL_88562a787e0a49c1a9db132ffae2de22"
          }
        },
        "be8bc0b49aae47bb9bd84cb86adba36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10cfb6695f37445ca833b2910b4c6ba6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2e40bd77324e4948a9663baf38b1432e",
            "value": "config.json:‚Äá100%"
          }
        },
        "d06f14c053d74be5a02c52f916db3de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f17f5d2a4af0487fbe21b7691ecd0a0e",
            "max": 547,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d01b0f6b8c2d429882e9c9d0f59badcd",
            "value": 547
          }
        },
        "26541e90673d476798f020b421c5c750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_742aa5ddfe744b2f931fca7fa8eb2758",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9099bdcf9580449a93565613c8075cc4",
            "value": "‚Äá547/547‚Äá[00:00&lt;00:00,‚Äá59.2kB/s]"
          }
        },
        "88562a787e0a49c1a9db132ffae2de22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10cfb6695f37445ca833b2910b4c6ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e40bd77324e4948a9663baf38b1432e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f17f5d2a4af0487fbe21b7691ecd0a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d01b0f6b8c2d429882e9c9d0f59badcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "742aa5ddfe744b2f931fca7fa8eb2758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9099bdcf9580449a93565613c8075cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68e4f471ead441f0a6c58a9a826a6fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f23b747a658149399b484550c1ced32f",
              "IPY_MODEL_94f2b7ca9cf8466585c04cda271293b0",
              "IPY_MODEL_1b54874dd8a4415b9bffca374232d010"
            ],
            "layout": "IPY_MODEL_a18d869f176f472e98660fa5ab9fa4ba"
          }
        },
        "f23b747a658149399b484550c1ced32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3feb7a1c0ec04790a275a3c034d4e336",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b9264bc3a34543d1b765f302b8dded1f",
            "value": "Loading‚Äápipeline‚Äácomponents...:‚Äá100%"
          }
        },
        "94f2b7ca9cf8466585c04cda271293b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ed7199353847b9b0b7db4e5d3c6321",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92784318294b4a7dbee7df0d842451d1",
            "value": 7
          }
        },
        "1b54874dd8a4415b9bffca374232d010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad779fb1c1794d729dbdcad058a4f14b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7f28a7109b574dd7941b5f969af40992",
            "value": "‚Äá7/7‚Äá[00:02&lt;00:00,‚Äá‚Äá2.86it/s]"
          }
        },
        "a18d869f176f472e98660fa5ab9fa4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3feb7a1c0ec04790a275a3c034d4e336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9264bc3a34543d1b765f302b8dded1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5ed7199353847b9b0b7db4e5d3c6321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92784318294b4a7dbee7df0d842451d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad779fb1c1794d729dbdcad058a4f14b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f28a7109b574dd7941b5f969af40992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBYGyE7RpOSa",
        "outputId": "15413808-9d89-43f5-c0f0-6a92ecf6ded3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import base64\n",
        "\n",
        "# -----------------------------------------------\n",
        "# 1. Set the folder paths\n",
        "# -----------------------------------------------\n",
        "# Folder containing your original images\n",
        "INPUT_FOLDER = \"/content/drive/MyDrive/new dataset/new dataset\"\n",
        "# Output JSON file path\n",
        "JSON_OUTPUT = \"/content/dataset.json\"\n",
        "\n",
        "# -----------------------------------------------\n",
        "# 2. Create a dictionary to hold file names and image data\n",
        "# -----------------------------------------------\n",
        "image_data_dict = {}\n",
        "\n",
        "# Loop through each file in the input folder\n",
        "for filename in os.listdir(INPUT_FOLDER):\n",
        "    # Check if the file is an image by extension\n",
        "    if not any(filename.lower().endswith(ext) for ext in [\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\"]):\n",
        "        continue\n",
        "\n",
        "    file_path = os.path.join(INPUT_FOLDER, filename)\n",
        "\n",
        "    # Read the image in binary mode and encode it in base64\n",
        "    with open(file_path, \"rb\") as image_file:\n",
        "        encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "    # Save the encoded string in the dictionary with the filename as the key\n",
        "    image_data_dict[filename] = encoded_string\n",
        "\n",
        "# -----------------------------------------------\n",
        "# 3. Write the dictionary to a JSON file\n",
        "# -----------------------------------------------\n",
        "with open(JSON_OUTPUT, \"w\") as json_file:\n",
        "    json.dump(image_data_dict, json_file, indent=4)\n",
        "\n",
        "print(f\"JSON file saved at: {JSON_OUTPUT}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3_EsxOWezen",
        "outputId": "e2902714-2517-44d5-c4a3-9c16408998da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON file saved at: /content/dataset.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39EoFXr0ehQ2",
        "outputId": "98b600cb-f822-45df-f29d-caa17e101fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì∏ Found 13 images. Starting augmentation...\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1c_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1c_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1c_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1c_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1e_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1e_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1e_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1e_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1k_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1k_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1k_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1k_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1f_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1f_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1f_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1f_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1g_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1g_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1g_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1g_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1m_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1m_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1m_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1m_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1q_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1q_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1q_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1q_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1l_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1l_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1l_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1l_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1b_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1b_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1b_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1b_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1h_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1h_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1h_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1h_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1j_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1j_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1j_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1j_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1d_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1d_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1d_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1d_aug3.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1a_orig.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1a_aug1.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1a_aug2.jpg\n",
            "‚úÖ Saved: /content/floorplan_augmented/apartment-floor-plan-1a_aug3.jpg\n",
            "‚úÖ Data augmentation completed! Augmented images are saved in: /content/floorplan_augmented\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from albumentations import (\n",
        "    Compose, HorizontalFlip, RandomRotate90, ShiftScaleRotate,\n",
        "    RandomBrightnessContrast, Resize\n",
        ")\n",
        "from PIL import Image\n",
        "\n",
        "# Define paths\n",
        "INPUT_FOLDER = \"/content/drive/MyDrive/new dataset/new dataset\"  # Folder with original images\n",
        "AUGMENTED_FOLDER = \"/content/floorplan_augmented\"    # Folder to store augmented images\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(AUGMENTED_FOLDER, exist_ok=True)\n",
        "\n",
        "# Define augmentation pipeline: resize to 512x512, then apply random augmentations\n",
        "augmentations = Compose([\n",
        "    Resize(512, 512),                   # Resize to 512x512\n",
        "    HorizontalFlip(p=0.5),               # Random horizontal flip\n",
        "    RandomRotate90(p=0.5),               # Random rotation by 90 degrees\n",
        "    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "    RandomBrightnessContrast(p=0.5)\n",
        "])\n",
        "\n",
        "# Function to save images using PIL\n",
        "def save_image(image_array, save_path):\n",
        "    try:\n",
        "        image_pil = Image.fromarray(image_array)\n",
        "        image_pil.save(save_path)\n",
        "        print(f\"‚úÖ Saved: {save_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error saving {save_path}: {e}\")\n",
        "\n",
        "# Function to augment a single image\n",
        "def augment_image(image_path, save_path, num_augmented=3):\n",
        "    # Check if image exists and is readable\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"‚ùå Error loading image: {image_path}\")\n",
        "        return\n",
        "\n",
        "    # Convert BGR (OpenCV format) to RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    filename, ext = os.path.splitext(os.path.basename(image_path))\n",
        "\n",
        "    # Save the original image (resized)\n",
        "    resized = augmentations(image=image)['image']\n",
        "    orig_save_path = os.path.join(save_path, f\"{filename}_orig{ext}\")\n",
        "    save_image(resized, orig_save_path)\n",
        "\n",
        "    # Generate and save augmented versions\n",
        "    for i in range(num_augmented):\n",
        "        augmented = augmentations(image=image)['image']\n",
        "        aug_save_path = os.path.join(save_path, f\"{filename}_aug{i+1}{ext}\")\n",
        "        save_image(augmented, aug_save_path)\n",
        "\n",
        "# Process all images in the input folder\n",
        "image_files = [f for f in os.listdir(INPUT_FOLDER) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "\n",
        "if not image_files:\n",
        "    print(\"‚ùå No images found in the input folder. Check the path.\")\n",
        "else:\n",
        "    print(f\"üì∏ Found {len(image_files)} images. Starting augmentation...\")\n",
        "\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(INPUT_FOLDER, img_file)\n",
        "        augment_image(img_path, AUGMENTED_FOLDER, num_augmented=3)\n",
        "\n",
        "    print(\"‚úÖ Data augmentation completed! Augmented images are saved in:\", AUGMENTED_FOLDER)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACE_HUB_HTTP_TIMEOUT\"] = \"60\"  # Increase timeout to 60 seconds\n"
      ],
      "metadata": {
        "id": "DehrV3uVgbfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "controlnet = ControlNetModel.from_pretrained(\n",
        "    \"lllyasviel/sd-controlnet-canny\",\n",
        "    torch_dtype=torch.float16,\n",
        "    local_files_only=True  # Use local cache only\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "CcgnnlVHgeYl",
        "outputId": "346836f6-c159-4895-fbff-8d2dd1ca3c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ControlNetModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0bd7e7d5043c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m controlnet = ControlNetModel.from_pretrained(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"lllyasviel/sd-controlnet-canny\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Use local cache only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ControlNetModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
        "from PIL import Image\n",
        "from diffusers import ControlNetModel, StableDiffusionPipeline, DDPMScheduler\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Custom Dataset Definition\n",
        "# ----------------------------\n",
        "AUGMENTED_FOLDER = \"/content/floorplan_augmented\"\n",
        "\n",
        "class FloorPlanDatasetFolder(Dataset):\n",
        "    def __init__(self, folder, transform=None):\n",
        "        self.folder = folder\n",
        "\n",
        "        # Check if the folder exists\n",
        "        if not os.path.exists(folder) or not os.path.isdir(folder):\n",
        "            raise ValueError(f\"Dataset folder '{folder}' does not exist or is not a directory.\")\n",
        "\n",
        "        # Get list of image files\n",
        "        self.filenames = [\n",
        "            f for f in os.listdir(folder)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))\n",
        "        ]\n",
        "\n",
        "        # Check if dataset is empty\n",
        "        if len(self.filenames) == 0:\n",
        "            raise ValueError(f\"No valid image files found in '{folder}'. Please check the dataset.\")\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.filenames[idx]\n",
        "        image_path = os.path.join(self.folder, filename)\n",
        "\n",
        "        # Load image safely\n",
        "        try:\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error loading image {image_path}: {e}\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        prompt = f\"Floor plan: {os.path.splitext(filename)[0]}\"\n",
        "        return {\"image\": image, \"prompt\": prompt}\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Image Transformations\n",
        "# ----------------------------\n",
        "transform = Compose([\n",
        "    Resize((512, 512)),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Try to create the dataset and print some debug info\n",
        "try:\n",
        "    dataset = FloorPlanDatasetFolder(folder=AUGMENTED_FOLDER, transform=transform)\n",
        "    print(f\"Loaded dataset with {len(dataset)} images.\")\n",
        "except ValueError as e:\n",
        "    print(f\"Dataset Error: {e}\")\n",
        "    dataset = None  # Avoid crashing later\n",
        "\n",
        "# Only create a DataLoader if the dataset is valid\n",
        "if dataset:\n",
        "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "else:\n",
        "    raise RuntimeError(\"Dataset could not be loaded. Check dataset folder and file format.\")\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Load Pre-trained Models and Scheduler\n",
        "# ----------------------------\n",
        "# Load models in float32 instead of float16 for training\n",
        "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    controlnet=controlnet\n",
        ")\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# Use DDPM noise scheduler\n",
        "noise_scheduler = DDPMScheduler(\n",
        "    beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Fine-Tuning with Stable Diffusion Loss (Fixed)\n",
        "# ----------------------------\n",
        "optimizer = torch.optim.AdamW(pipe.unet.parameters(), lr=5e-6)  # Reduced LR for stability\n",
        "scaler = GradScaler()  # Helps with mixed precision training\n",
        "\n",
        "num_epochs = 1  # Adjust as needed\n",
        "pipe.unet.train()\n",
        "pipe.vae.eval()\n",
        "pipe.text_encoder.eval()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        images = batch[\"image\"].to(\"cuda\")\n",
        "        prompts = batch[\"prompt\"]\n",
        "\n",
        "        # ----------------------------\n",
        "        # a. Encode Images into Latents with Autocast\n",
        "        # ----------------------------\n",
        "        with torch.no_grad(), autocast(enabled=True):\n",
        "            latents = pipe.vae.encode(images).latent_dist.sample()\n",
        "            latents = latents * pipe.vae.config.scaling_factor\n",
        "\n",
        "        # ----------------------------\n",
        "        # b. Sample Noise and Timesteps\n",
        "        # ----------------------------\n",
        "        noise = torch.randn_like(latents).to(\"cuda\")\n",
        "        batch_size = latents.shape[0]\n",
        "        timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (batch_size,), device=\"cuda\").long()\n",
        "\n",
        "        # Add noise to latents\n",
        "        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
        "\n",
        "        # ----------------------------\n",
        "        # c. Tokenize Prompts and Get Text Embeddings\n",
        "        # ----------------------------\n",
        "        tokenized = pipe.tokenizer(\n",
        "            prompts, padding=\"max_length\", truncation=True, max_length=77, return_tensors=\"pt\"\n",
        "        )\n",
        "        input_ids = tokenized.input_ids.to(\"cuda\")\n",
        "        with torch.no_grad(), autocast(enabled=True):\n",
        "            text_embeddings = pipe.text_encoder(input_ids).last_hidden_state\n",
        "\n",
        "        # ----------------------------\n",
        "        # d. Predict the Noise using UNet with Gradient Scaling\n",
        "        # ----------------------------\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(enabled=True):\n",
        "            noise_pred = pipe.unet(noisy_latents, timesteps, encoder_hidden_states=text_embeddings).sample\n",
        "\n",
        "            # Check for NaNs before computing loss\n",
        "            if torch.isnan(noise_pred).any():\n",
        "                print(f\"Warning: NaN detected in UNet output. Skipping batch {batch_idx}\")\n",
        "                continue\n",
        "\n",
        "            # Compute MSE loss\n",
        "            loss = F.mse_loss(noise_pred, noise)\n",
        "\n",
        "        # ----------------------------\n",
        "        # e. Backpropagation with Gradient Clipping\n",
        "        # ----------------------------\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(pipe.unet.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        if batch_idx % 5 == 0:  # Print every 5 batches\n",
        "            print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item()}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "pipe.save_pretrained(\"fine_tuned_floorplan_model\")\n",
        "print(\"Fine-tuning completed and model saved.\")\n"
      ],
      "metadata": {
        "id": "uZu-7TgNhkbr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bcd6e7be5b444bb88000a63176a695eb",
            "66a7ab1c786f46e587236f08b7e3b079",
            "9d519a348695414c9c8b9da328f37e97",
            "b5df8bc10f3c401cb45b3898a9fde587",
            "288e9a2026eb4f7496bd5d3fd47991ab",
            "b278e708db7c4637b29c26926fcfc1e4",
            "9aeb363eac8e47069992acf1cb716663",
            "0cf98bb12e7945518f6568ea49069c28",
            "ac8d68633b454c51946c69b9e67bf7d8",
            "6c09ac5d6ea541a9b3a630262aef58b6",
            "90d9039fc94640d2b5f52cc60f4f7633",
            "f6c3d3f691f44f3ea10b5818e97825f6",
            "be8bc0b49aae47bb9bd84cb86adba36a",
            "d06f14c053d74be5a02c52f916db3de2",
            "26541e90673d476798f020b421c5c750",
            "88562a787e0a49c1a9db132ffae2de22",
            "10cfb6695f37445ca833b2910b4c6ba6",
            "2e40bd77324e4948a9663baf38b1432e",
            "f17f5d2a4af0487fbe21b7691ecd0a0e",
            "d01b0f6b8c2d429882e9c9d0f59badcd",
            "742aa5ddfe744b2f931fca7fa8eb2758",
            "9099bdcf9580449a93565613c8075cc4",
            "68e4f471ead441f0a6c58a9a826a6fb6",
            "f23b747a658149399b484550c1ced32f",
            "94f2b7ca9cf8466585c04cda271293b0",
            "1b54874dd8a4415b9bffca374232d010",
            "a18d869f176f472e98660fa5ab9fa4ba",
            "3feb7a1c0ec04790a275a3c034d4e336",
            "b9264bc3a34543d1b765f302b8dded1f",
            "a5ed7199353847b9b0b7db4e5d3c6321",
            "92784318294b4a7dbee7df0d842451d1",
            "ad779fb1c1794d729dbdcad058a4f14b",
            "7f28a7109b574dd7941b5f969af40992"
          ]
        },
        "outputId": "a55b2ac8-8077-48f8-c178-7c58b748301d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with 52 images.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcd6e7be5b444bb88000a63176a695eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6c3d3f691f44f3ea10b5818e97825f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Keyword arguments {'controlnet': ControlNetModel(\n",
            "  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (time_proj): Timesteps()\n",
            "  (time_embedding): TimestepEmbedding(\n",
            "    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
            "    (act): SiLU()\n",
            "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "  )\n",
            "  (controlnet_cond_embedding): ControlNetConditioningEmbedding(\n",
            "    (conv_in): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (blocks): ModuleList(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): Conv2d(32, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (5): Conv2d(96, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (conv_out): Conv2d(256, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (down_blocks): ModuleList(\n",
            "    (0): CrossAttnDownBlock2D(\n",
            "      (attentions): ModuleList(\n",
            "        (0-1): 2 x Transformer2DModel(\n",
            "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (transformer_blocks): ModuleList(\n",
            "            (0): BasicTransformerBlock(\n",
            "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "              (attn1): Attention(\n",
            "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                (to_out): ModuleList(\n",
            "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "              (attn2): Attention(\n",
            "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                (to_out): ModuleList(\n",
            "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "              (ff): FeedForward(\n",
            "                (net): ModuleList(\n",
            "                  (0): GEGLU(\n",
            "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                  )\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (resnets): ModuleList(\n",
            "        (0-1): 2 x ResnetBlock2D(\n",
            "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (nonlinearity): SiLU()\n",
            "        )\n",
            "      )\n",
            "      (downsamplers): ModuleList(\n",
            "        (0): Downsample2D(\n",
            "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): CrossAttnDownBlock2D(\n",
            "      (attentions): ModuleList(\n",
            "        (0-1): 2 x Transformer2DModel(\n",
            "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (transformer_blocks): ModuleList(\n",
            "            (0): BasicTransformerBlock(\n",
            "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "              (attn1): Attention(\n",
            "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                (to_out): ModuleList(\n",
            "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "              (attn2): Attention(\n",
            "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                (to_out): ModuleList(\n",
            "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "              (ff): FeedForward(\n",
            "                (net): ModuleList(\n",
            "                  (0): GEGLU(\n",
            "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                  )\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (resnets): ModuleList(\n",
            "        (0): ResnetBlock2D(\n",
            "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (nonlinearity): SiLU()\n",
            "          (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): ResnetBlock2D(\n",
            "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (nonlinearity): SiLU()\n",
            "        )\n",
            "      )\n",
            "      (downsamplers): ModuleList(\n",
            "        (0): Downsample2D(\n",
            "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): CrossAttnDownBlock2D(\n",
            "      (attentions): ModuleList(\n",
            "        (0-1): 2 x Transformer2DModel(\n",
            "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (transformer_blocks): ModuleList(\n",
            "            (0): BasicTransformerBlock(\n",
            "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "              (attn1): Attention(\n",
            "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                (to_out): ModuleList(\n",
            "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "              (attn2): Attention(\n",
            "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                (to_out): ModuleList(\n",
            "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "              (ff): FeedForward(\n",
            "                (net): ModuleList(\n",
            "                  (0): GEGLU(\n",
            "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                  )\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (resnets): ModuleList(\n",
            "        (0): ResnetBlock2D(\n",
            "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (nonlinearity): SiLU()\n",
            "          (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): ResnetBlock2D(\n",
            "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (nonlinearity): SiLU()\n",
            "        )\n",
            "      )\n",
            "      (downsamplers): ModuleList(\n",
            "        (0): Downsample2D(\n",
            "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): DownBlock2D(\n",
            "      (resnets): ModuleList(\n",
            "        (0-1): 2 x ResnetBlock2D(\n",
            "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (nonlinearity): SiLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (controlnet_down_blocks): ModuleList(\n",
            "    (0-3): 4 x Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (4-6): 3 x Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (7-11): 5 x Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (controlnet_mid_block): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (mid_block): UNetMidBlock2DCrossAttn(\n",
            "    (attentions): ModuleList(\n",
            "      (0): Transformer2DModel(\n",
            "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (transformer_blocks): ModuleList(\n",
            "          (0): BasicTransformerBlock(\n",
            "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn1): Attention(\n",
            "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "              (to_out): ModuleList(\n",
            "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                (1): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn2): Attention(\n",
            "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "              (to_out): ModuleList(\n",
            "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                (1): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "            (ff): FeedForward(\n",
            "              (net): ModuleList(\n",
            "                (0): GEGLU(\n",
            "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                )\n",
            "                (1): Dropout(p=0.0, inplace=False)\n",
            "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (resnets): ModuleList(\n",
            "      (0-1): 2 x ResnetBlock2D(\n",
            "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "        (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (nonlinearity): SiLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")} are not expected by StableDiffusionPipeline and will be ignored.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68e4f471ead441f0a6c58a9a826a6fb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-eb790beb2296>:97: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Helps with mixed precision training\n",
            "<ipython-input-30-eb790beb2296>:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast(enabled=True):\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:140: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
            "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
            "<ipython-input-30-eb790beb2296>:133: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast(enabled=True):\n",
            "<ipython-input-30-eb790beb2296>:140: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=True):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 20413 has 14.72 GiB memory in use. Of the allocated memory 14.43 GiB is allocated by PyTorch, and 156.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-eb790beb2296>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"betas\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             has_complex = self._init_group(\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_init_group\u001b[0;34m(self, group, params_with_grad, grads, amsgrad, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 )\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 state[\"exp_avg_sq\"] = torch.zeros_like(\n\u001b[0m\u001b[1;32m    176\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 20413 has 14.72 GiB memory in use. Of the allocated memory 14.43 GiB is allocated by PyTorch, and 156.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-AEKLTfHqWKE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}